{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA620: Week 10/11 Assignment\n",
    "\n",
    "> #### Bryant Chang, Thomas Detzel, Sandipayan Nandi, and Erik Nylander\n",
    "\n",
    "For this project, we use the Reuters Corpus ([Reuters 21578](http://disi.unitn.it/moschitti/corpora.htm)) data set. We especifically use the corpus included in the [NLTK.Corpus](http://www.nltk.org/book/ch02.html) package. It contains 10,788 news documents totalling 1.3 \n",
    "million words. The documents have been classified into 90 topics, and grouped into two sets, called \"training\" and \"test\".\n",
    "\n",
    "Categories in the Reuters Corpus overlap each other, because a news story often covers multiple topics. Our goal is to build a model with the training dataset in order to predict the class of new documents in the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk, re, pprint\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.collocations import BigramCollocationFinder\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from itertools import *\n",
    "import codecs\n",
    "import urllib2\n",
    "import sys\n",
    "import os\n",
    "import string\n",
    "import random\n",
    "import itertools as it\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "import matplotlib.colors as colors\n",
    "%matplotlib inline\n",
    "plot.rcParams['figure.figsize'] = (21, 14)\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "# Python 2 users only\n",
    "from __future__ import division  \n",
    "from __future__ import unicode_literals\n",
    "from __future__ import print_function\n",
    "\n",
    "# Load the corpus\n",
    "from nltk.corpus import reuters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10788"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of documents\n",
    "len(reuters.fileids())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1720901"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of words\n",
    "len(reuters.words())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41600"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of distinct words\n",
    "len(set(reuters.words()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test/14826',\n",
       " 'test/14828',\n",
       " 'test/14829',\n",
       " 'test/14832',\n",
       " 'test/14833',\n",
       " 'test/14839',\n",
       " 'test/14840',\n",
       " 'test/14841',\n",
       " 'test/14842',\n",
       " 'test/14843']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first ten documents\n",
    "reuters.fileids()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['training/9982',\n",
       " 'training/9984',\n",
       " 'training/9985',\n",
       " 'training/9988',\n",
       " 'training/9989',\n",
       " 'training/999',\n",
       " 'training/9992',\n",
       " 'training/9993',\n",
       " 'training/9994',\n",
       " 'training/9995']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print last ten documents\n",
    "reuters.fileids()[10778:10788]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of categories\n",
    "len(reuters.categories())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'acq',\n",
       " u'alum',\n",
       " u'barley',\n",
       " u'bop',\n",
       " u'carcass',\n",
       " u'castor-oil',\n",
       " u'cocoa',\n",
       " u'coconut',\n",
       " u'coconut-oil',\n",
       " u'coffee']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first ten categories\n",
    "reuters.categories()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a document file, with each document as its category tag\n",
    "documents = [(list(reuters.words(fileid)), category)\n",
    "    for category in reuters.categories()\n",
    "    for fileid in reuters.fileids(category)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([u'SUMITOMO', u'BANK', u'AIMS', u'AT', u'QUICK'], u'acq')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check first one\n",
    "documents[0][0][:5], documents[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X.X create word_features from the text example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## word_features from text\n",
    "all_words = nltk.FreqDist(w.lower() for w in reuters.words())\n",
    "word_features = all_words.keys()[:2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# feature extractor: find whether a document contains any of the words in word_features\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'contains(s)', True),\n",
       " (u'contains(corporate)', False),\n",
       " (u'contains(casse)', False),\n",
       " (u'contains(pressed)', False),\n",
       " (u'contains(jay)', False),\n",
       " (u'contains(pfr)', False),\n",
       " (u'contains(barred)', False),\n",
       " (u'contains(broaden)', False),\n",
       " (u'contains(workforces)', False),\n",
       " (u'contains(aberrational)', False)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test it - show first 10 \n",
    "Counter(document_features('Reuters/training/cpu/0003746')).most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create feature set\n",
    "featuresets = [(document_features(d), c) for (d,c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define train and test sets\n",
    "train_set, test_set = featuresets[100:], featuresets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train classifier\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 63.0%.\n"
     ]
    }
   ],
   "source": [
    "# test classifier\n",
    "print(\"Accuracy is {}%.\".format(nltk.classify.accuracy(classifier, test_set)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "       contains(guilder) = True              dfl : acq    =   1324.2 : 1.0\n",
      "       contains(heating) = True             heat : acq    =   1021.5 : 1.0\n",
      "           contains(wet) = True           copra- : earn   =    991.2 : 1.0\n",
      "       contains(opposed) = True           copra- : earn   =    991.2 : 1.0\n",
      "      contains(shortage) = True           copra- : earn   =    991.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X.0 Refine the word_features to exclude stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# remove stop words\n",
    "r_words = [word.lower() for word in reuters.words() if word.isalpha()]\n",
    "stopwords = stopwords.words('english')\n",
    "r_words = [w for w in r_words if w not in stopwords]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create list of 2,000 most common words\n",
    "all_words = nltk.FreqDist(r_words)\n",
    "word_features2 = all_words.most_common(2000)\n",
    "\n",
    "# get just the words, no counts\n",
    "word_features2 = [w for (w,v) in word_features2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# update feature extractor with new features\n",
    "def document_features(document):\n",
    "    document_words = set(document)\n",
    "    features = {}\n",
    "    for word in word_features2:\n",
    "        features['contains(%s)' % word] = (word in document_words)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create feature set 2\n",
    "featuresets2 = [(document_features(d), c) for (d,c) in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define train and test sets\n",
    "train_set2, test_set2 = featuresets2[100:], featuresets2[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# train classifier\n",
    "classifier2 = nltk.NaiveBayesClassifier.train(train_set2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 78.0%.\n"
     ]
    }
   ],
   "source": [
    "# test classifier\n",
    "print(\"Accuracy is {}%.\".format(nltk.classify.accuracy(classifier2, test_set2)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "          contains(palm) = True           palm-o : earn   =   2611.1 : 1.0\n",
      "         contains(ounce) = True           pallad : earn   =   2312.9 : 1.0\n",
      "    contains(economists) = True             rand : earn   =   2312.9 : 1.0\n",
      "        contains(coffee) = True           coffee : earn   =   2256.3 : 1.0\n",
      "        contains(rubber) = True           rubber : earn   =   2246.8 : 1.0\n",
      "       contains(follows) = True           lin-oi : earn   =   2202.8 : 1.0\n",
      "         contains(index) = True              lei : earn   =   1899.9 : 1.0\n",
      "       contains(sorghum) = True           sorghu : earn   =   1850.3 : 1.0\n",
      "    contains(seasonally) = True           housin : earn   =   1825.2 : 1.0\n",
      "     contains(vegetable) = True           coconu : earn   =   1817.3 : 1.0\n"
     ]
    }
   ],
   "source": [
    "classifier2.show_most_informative_features(10)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
